{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor of importance for uploaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import joblib\n",
    "\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = pd.read_csv('data/predict.csv', encoding=\"cp1251\", sep=\";\")\n",
    "X_predict_prepared = X_predict.drop({'filename'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseCountVectorizer(sktext.CountVectorizer):\n",
    "    def transform(self, raw_documents, copy=True):\n",
    "        X = super().transform(raw_documents)\n",
    "        df = pd.DataFrame(X.toarray(), columns=self.get_feature_names())\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, raw_documents, y=None):\n",
    "        X = super().fit_transform(raw_documents, y=y)\n",
    "        df = pd.DataFrame(X.toarray(), columns=self.get_feature_names())\n",
    "        return df\n",
    "\n",
    "def prepareSentence(morph, russian_stopwords, sentence):\n",
    "    try:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "    except:\n",
    "        try:\n",
    "            words = sentence.split()\n",
    "        except:\n",
    "            return ''\n",
    "    words = [morph.parse(word)[0].normal_form for word in words]\n",
    "    words = [token for token in words if token not in russian_stopwords\\\n",
    "          and token != \" \" \\\n",
    "          and token.strip() not in punctuation]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def one_hot_encode(df, col):\n",
    "        df = df.copy()\n",
    "        return df.drop(col, axis=1).join(pd.get_dummies(df[col], prefix=col))\n",
    "    \n",
    "def prepareData(data):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    russian_stopwords = stopwords.words(\"russian\")\n",
    "    data = one_hot_encode(data, 'section')\n",
    "    data['text'] = data.apply(lambda row: prepareSentence(morph, russian_stopwords, row['text']), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict_prepared = prepareData(X_predict_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load(\"vectorizer-large.pkl\")\n",
    "X_predict_vectorized = vectorizer.transform(X_predict_prepared['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict_vectorized['section_common'] = X_predict_prepared.section_common\n",
    "X_predict_vectorized['section_respons'] = X_predict_prepared.section_respons\n",
    "X_predict_vectorized['section_rights'] = X_predict_prepared.section_rights\n",
    "X_predict_vectorized['section_tasks'] = X_predict_prepared.section_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_file = CatBoostClassifier()\n",
    "\n",
    "from_file.load_model(\"model-large.cbm\")\n",
    "predict = list(map(lambda x: round(x[1], 2), from_file.predict_proba(X_predict_vectorized)))\n",
    "X_predict['light'] = predict\n",
    "X_predict.to_csv('data/result.csv', sep = ';', encoding=\"cp1251\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
